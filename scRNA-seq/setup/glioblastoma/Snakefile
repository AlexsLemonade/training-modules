# Workflow for downloading and preprocessing smartseq scRNA data
configfile: "config.yaml"

import pandas as pd

basedir = config["base_dir"]

rule all:
    input:
        os.path.join(basedir, "qc_reports/fastqc/fastqc_report_all.csv"),
        os.path.join(basedir, "tximport/count_matrix.tsv")

checkpoint sample_list:
    # create the sample list for the given SRP accession
    output:
        "{base}/sample_list.csv"
    params:
        srp = config['SRP']
    shell:
        "Rscript get_srp_table.R"
        " --srp {params.srp}"
        " --outfile {output}"
        " --paired"

rule get_fastqs:
    # download fastqc files for a particular run
    input: 
        "{base}/sample_list.csv"
    output:
        # make these temporary to save space
        R1 = temp("{base}/fastq/{run_id}/{run_id}_1.fastq.gz"),
        R2 = temp("{base}/fastq/{run_id}/{run_id}_2.fastq.gz")
    run:
        sample_df = pd.read_csv(input[0])
        # filter sample table to the sample required 
        # to create a given output file (defined by run_id)
        samples = sample_df[sample_df['run_accession'] == wildcards.run_id]
        # create urls and fetch
        urls = " ".join([f"ftp://{url}" for url in samples['fastq_ftp']])
        shell(f"wget {urls} -P {wildcards.base}/fastq/{wildcards.run_id} -q")

rule fastqc:
    # run fastqc
    input:
        "{base}/fastq/{run}/{sample}.fastq.gz"
    output:
        "{base}/qc_reports/fastqc/{run}/{sample}_fastqc.html"
    shell:
        "fastqc {input} --outdir $(dirname {output}) -q"

def aggregate_fastqc(wildcards):
    """
    Use the sample list file to generate the full fastqc file list
    """
    with checkpoints.sample_list.get(**wildcards).output[0].open() as f:
        sample_df = pd.read_csv(f)
    # get the run and fastq filename from the last two elements of the ftp field
    run_fastq = [f.split("/")[-2:] for f in sample_df['fastq_ftp']]
    # swap the fastq extension to make the fastqc file name and join back to partial paths 
    qc_paths = [os.path.join(run, fastq.replace('.fastq.gz', '_fastqc.html') )
                for run, fastq in run_fastq]
    # create the full paths
    qc_fullpaths = [os.path.join(wildcards.base, "qc_reports", "fastqc", qc) 
                    for qc in qc_paths]
    return(qc_fullpaths)

rule fastqc_summary:
    # join all fastqc results into a summary table
    input:
        aggregate_fastqc
    output:
        report_table = "{base}/qc_reports/fastqc/fastqc_report_all.csv",
        filtered = "{base}/qc_reports/fastqc/fastqc_report_filtered.csv"
    params:
        dir = "{base}/qc_reports/fastqc"
    shell:
        "Rscript summarize_fastqc.R"
        " -d {params.dir}"
        " -t {output.report_table}"
        " -f {output.filtered}"


rule salmon_quant:
    # run salmon quantification
    input:
        index = config['salmon_index'],
        R1 = "{base}/fastq/{run_id}/{run_id}_1.fastq.gz",
        R2 = "{base}/fastq/{run_id}/{run_id}_2.fastq.gz"
    output:
        dir = directory("{base}/salmon_quant/{run_id}"), 
        quant_file = "{base}/salmon_quant/{run_id}/quant.sf"
    threads: 4
    shell:
        "salmon quant" 
        " -i {input.index}"
        " -l A"
        " -1 {input.R1}"
        " -2 {input.R2}"
        " -o {output.dir}"
        " --validateMappings"
        " --rangeFactorizationBins 4"
        " --gcBias"
        " --seqBias"
        " --threads {threads}"
        " --quiet"

def aggregate_salmon(wildcards):
    """
    Use the sample list file to generate the full quantsf file list
    """
    with checkpoints.sample_list.get(**wildcards).output[0].open() as f:
        sample_df = pd.read_csv(f)
    run_ids = sample_df['run_accession']
    # create the quant.sf paths from the run_ids
    quant_paths = [os.path.join(wildcards.base, "salmon_quant", run, "quant.sf")
                   for run in run_ids]
    return(quant_paths)

rule salmon_matrix:
    # Join the salmon results into a single matrix with tximport
    input:
        files = aggregate_salmon,
        tx2gene = config['tx2gene']
    output:
        gene_matrix = "{base}/tximport/count_matrix.tsv",
        txi_obj = "{base}/tximport/tximport_obj.RDS"
    params:
        quant_dir = "{base}/salmon_quant/",
        map_cutoff = 0.3
    shell:
        "Rscript make_count_matrix.R"
        " -d {params.quant_dir}"
        " -t {input.tx2gene}"
        " -m {params.map_cutoff}"
        " -o {output.gene_matrix}"
        " -r {output.txi_obj}"