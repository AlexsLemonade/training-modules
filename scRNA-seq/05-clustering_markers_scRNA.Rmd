---
title: "Clustering cells and finding marker genes scRNA-seq data"
author: CCDL for ALSF
date: 2021
output:
  html_notebook: 
    toc: true
    toc_float: true
---

## Objectives

This notebook will demonstrate how to:

- Annotate clusters of cells in single-cell data
- Compare different clustering methods
- Identify marker genes that can be used to differentiate clusters

---

## Set Up

### Load libraries
```{r setup}
# Load libraries
library(ggplot2)
library(scater)
library(scran)
# clustering tools
library(bluster)

# Magrittr pipe
library(magrittr)

# Setting the seed for reproducibility
set.seed(12345)
```

```{r filepaths}
# main data directory
data_dir <- file.path("data", "hodgkins")

# normalized data file
normalized_rds <- file.path(data_dir, "normalized", "normalized_hodgkins_sce.rds")

# Output directory for markers
marker_dir <- file.path("analysis", "hodgkins", "markers")
if (!dir.exists(marker_dir)) {
  dir.create(marker_dir, recursive = TRUE)
}
```

```{r read data}
hodgkins_sce <- readr::read_rds(normalized_rds)
```

## Assigning cell clusters

Source of lots of info: https://bioconductor.org/books/release/OSCA/clustering.html

When we performed dimensionality reduction on our single cell data, we could see visually that the cells tended cluster together into groups. 
To the extent that such clustering is a real biological phenomenon, representing cells with similar patterns of gene expression, we might like to identify distinct groups that we can name and assign a label to.
Ultimately, we would hope that these labels correspond to previously identified (or newly identified!) cell types, and that we can use that information to provide more insight into the results of our experiment.

There are a number of methods to identify clusters and assign cells to those in multidimensional data like the single cell data we have.
We will explore a few of those methods here.

### k-means clustering

The first method we will try is k-means clustering.
This clustering method seeks to find a way to divide the cells into groups such that the variation within each group is as small as possible and the variation between groups is maximized.
It turns out that is a pretty hard problem to solve exactly, but we can do pretty well with an algorithm that starts by randomly assigning our cells to clusters.
We find the centers of each of those random clusters, then reassign cells to clusters by finding which of the centers each point is nearest to.
We then find the centers of these new clusters, reassign cells to with these new centers, and repeat until the cluster assignments stop changing. 

It is important to emphasize k-means algorithm requires us to pick the number of clusters we want to use.
There are some heuristics we can use for deciding the "correct" number of clusters, but we will not be exploring those now. 
For an intuitive visualization of the general k-means method, you might find [this StatsQuest video](https://www.youtube.com/watch?v=4b5d3muPQmA) useful, and for more discussion of the method in a single-cell context, the [Orchestrating Single-Cell Analysis book chapter on k-means](https://bioconductor.org/books/release/OSCA/clustering.html#k-means-clustering) is a good reference.


We are going to use the function `clusterRows()` from the  Bioconductor `bluster` package for our clustering. 
This function takes a matrix where each sample (cell in our case) is a row and each column is a feature.
The matrix of counts (or normalized counts) by cells in our `SingleCellExperiment` object is the wrong orientation, so at a minimum we would have to transpose that matrix before proceeding. 

However, clustering algorithms like k-means can be a bit slow with as many features as the number of genes that we have in our data set, so we would rather not use the raw data.
There is also a potential concern that noise in the raw data might disrupt the clustering algorithm, so it would be best to use some kind of dimensionality reduction algorithm first. 
But we still want to maintain a good number of dimensions, so our old friend PCA is a good (and very standard) choice.

Thankfully, we already computed *and stored* a matrix with reduced dimensions with the `runPCA()` function. 
We will extract that from the `SingleCellExperiment` object with the `reducedDim()` function, which conveniently returns a matrix with the cells as rows, so we can use that directly!


```{r kmeans_7}
# set the number of clusters:
k <- 7

# extract the principal components matrix
hodgkins_pca <- reducedDim(hodgkins_sce, "PCA")

# perform the clustering
kclusters <- clusterRows(hodgkins_pca, KmeansParam(centers = k))
```

The `clusterRows()` function returned a vector of cluster assignments as integers, but the numerical values have no inherent meaning. 
For plotting we will want to convert those to a factor, so R is not tempted to treat them as a continuous variable.

We can also store them back into the column (cell) information table of the original object for convenient storage and later use.

```{r store_kclusters}
hodgkins_sce$kcluster <- factor(kclusters)
```

Now we can plot the results and see how the clustering looks, using the `scater` function `plotReducedDim()`, but now coloring the points by our clustering results.
We will start by using the UMAP coordinates for the plot.
Note that this does require that the cluster identities were stored in the `SingleCellExperiment` object.

```{r plot_k}
plotReducedDim(hodgkins_sce, "UMAP", colour_by = "kcluster")
```

- Do those clusters line up with what you might have expected if you were doing this by eye?
- If we repeat this, do we get the same number of clusters?
- What happens if we change the number of clusters?
- What do the results look like if you plot with the PCA or TSNE coordinates? 

We will have time to explore some of these questions in a bit. 
One thing worth noting right away though is that cluster numbers here and in the future are random.  
Even if we got exactly the same logical clusters across runs (unlikely!), we wouldn't expect the numbers to be the same or stable.

### Graph-based clustering

Another common type of clustering method for single cell data is graph-based clustering. 
This works by identifying a set of nearest neighbors for each cell that have similar expression profiles to that cell, then connecting each cell to those neighbors in a network graph. 
The connections are weighted by how similar each cell is to its neighbors.

We then break the network up by identifying clusters of cells that are more connected to each other than they are to cells outside the clusters. 

To apply this, we will use the same `bluster::clusterRows()` function as before, but we will change the second argument from `KmeansParam()` to `NNGraphParam()` to tell it that we want to use a nearest-neighbor graph-based method. 
We can then supply parameters to `NNGraphParam()` to adjust the details of the algorithm.

Here we will use `k` to specify the number of neighbors to use when building the graph and `cluster.fun` to specify the algorithm for identifying the clusters within the graph.

- Despite sharing a letter, `k` here and the one from k-means clustering are not the same thing!
In this case, we are telling the algorithm how many neighbor connections to make for each cell, not the final number of clusters, which will be determined by the algorithm we used for that step.

- The options for `cluster.fun` include `walktrap` (the default), and `louvain`, which is used by default in some other common tools like [`Seurat`](https://satijalab.org/seurat/).

In the example below, we will use the default values for these two arguments.

```{r nnclust, live = TRUE}
# run the clustering algorithm
nnclusters <- clusterRows(
  hodgkins_pca, 
  NNGraphParam(k = 10, 
               cluster.fun = "walktrap")
  )
# store cluster results in the SCE object
hodgkins_sce$nncluster <- factor(nnclusters)
```

Now we can plot the results of our graph-based clustering. 
This time we will also use the `text_by` argument to include the cluster ids directly on the plot. 

```{r plot_nnclust, live = TRUE}
plotReducedDim(hodgkins_sce, 
               "UMAP", 
               colour_by = "nncluster", 
               text_by = "nncluster")
```

- How does that compare to the k-means clustering result?


### Parameters matter!

As we did with UMAP, lets take a bit of time to explore the effects of the various parameter choices that we have on the output results.

To streamline the testing, we will again create a function to perform the clustering and plotting in a single step.
One extra advantage of this approach is that the modified `SingleCellExperiment` objects we create inside the function won't affect the `hodgkins_sce` object that we have.
If we did want to save one of these results, we would have to do the clustering step outside this function (or modify the function to return the modified object).

```{r clusterplot_function}
clusterPlot <- function(sce, cluster_param, plot_dim = "UMAP"){
  # cluster and plot cells from a SingleCellExperiment object
  # cluster_param is a BlusterParam object: 
  #     typically one of HclustParam(), KmeansParam() or NNGraphParam() 
  # plot_dim is the reduced dimensionality coordinates used for plotting:
  #     "PCA", "UMAP", or "TSNE"
  pc_matrix <- reducedDim(sce, "PCA")
  clusters <- bluster::clusterRows(pc_matrix, cluster_param) %>% factor()
  sce$cluster <- factor(clusters)
  scater::plotReducedDim(sce, plot_dim, colour_by = "cluster", text_by ="cluster")
}
```


This function still requires a bit of care to use, mostly because there is so much room for variation in the clustering algorithms.

We will briefly outline some of the parameters you might explore for each of the clustering algorithms.
For more you will want to look at the help pages for each of the `*Params()` functions.

- `KmeansParam()` (see also `?kmeans`)
  - `centers`: the number of clusters to be assigned 
  - `nstart`: the number of random starting sets to use: the best result will be returned.

- `NNGraphParam()` 
  - `k`: the number of neighbors for each cell to use when constructing the graph
  - `type`: how the neighbor graph is weighted. 
  The options are `rank` (default), `number` and `jaccard`, with the last of those being the default in `Seurat`.
  For more details see `?makeSNNGraph`
  - `cluster.fun`: Which cluster detection algorithm to use. 
  The options are many, but common choices are `walktrap` (default) and `louvain` (used by `Seurat`).
  
- `HclustParam()` performs hierarchical clustering, which we have not discussed here. 
This algorithm progressively joins the most similar cells, until all cells have been incorporated into a tree of similarity. 
Then one of a number of algorithms can be applied to split that tree into subtrees to assign clusters.
You will probably be most interested in the `cut.number` parameter which allows you to specify the number of clusters: the default parameters tend to result in *a lot* of clusters.

Take some time below to explore different clustering algorithms and parameters!
You might also note how the results can change from one run to the next with no changes in parameters.
Do different clustering algorithms tend to agree with what you "see" in the dimensionality reduction plots? 
Is that dependent on which set of dimensions you use?

```{r clusterplot1, live = TRUE}
clusterPlot(hodgkins_sce, 
            KmeansParam(centers = 12, nstart = 10), 
            plot_dim = "TSNE")
```


```{r clusterplot2, live = TRUE}
clusterPlot(hodgkins_sce, 
            NNGraphParam(k = 20, 
                         type = "jaccard", 
                         cluster.fun = "louvain"), 
            plot_dim = "UMAP")
```


```{r clusterplot3, live = TRUE}
clusterPlot(hodgkins_sce, 
            HclustParam(cut.number = 10),
            plot_dim = "UMAP")
```


## Identifying marker genes

Assigning clusters is nice for visualization, but we would like to be able to move toward a biological interpretation of the clusters and identifying the cell types in each cluster.
To that end, we can identify marker genes that are differentially expressed among clusters. 

It is worth noting here that the statistical calculations here are more than a bit circular: we identified clusters first based on gene expression, then we are using those same clusters to find differences in gene expression. 
The result is that even if there were no *true* clusters, we would always find marker genes! 
For a much more technical exploration of this circularity (and a method to correct for it), see a preprint by [Gao et al. (2020)](https://arxiv.org/abs/2012.02936).
In light of this, it is better to think about marker gene identification as an aid in interpreting the clustering results (and possibly extending insights to new data sets), rather than results that should be interpreted on their own, and we should be extremely wary of justifying cluster assignments solely based on these results!
With that caveat, let's proceed.

To identify marker genes, we will use the `scran::findMarkers()` function, which will rank genes by their differential expression by calculating pairwise statistics among clusters.
We have a few options for how to determine the gene rankings and marker gene list for each cluster. 
At one end could include genes that are differentially expressed in *any* pairwise comparison against our focal cluster, or at the other we could only include genes that are differentially expressed in *all* comparisons with that cluster. 
We could also do something in between, including genes that differentiate the focal cluster from *some* fraction of the other clusters.
For now, we will use the `findMarkers()` function to rank the genes in each cluster by their combined scores against *all* other clusters. 

`findMarkers()` will return a list (technically a list-like object) of tables, one for each cell type, with statistics for each gene showing how well it differentiates that cell type against other types.


```{r find_markers}
markers <- scran::findMarkers(hodgkins_sce, 
                              groups = hodgkins_sce$nncluster, 
                              pval.type = "all")
```

Next we can look at one of those tables.
We will start with the first cluster, which we will select from the list using the R standard double bracket `[[1]]` notation.
We also doing a bit of transformation here to pull the gene name into a column of its own.

```{r marker_table}
markers[[1]] %>%
  as.data.frame() %>% # convert to a data frame
  tibble::rownames_to_column("gene")
```

Because we tend to like [tidy data](https://r4ds.had.co.nz/tidy-data.html), here we use a `tidyverse` function from the [`purrr` package](https://purrr.tidyverse.org) to apply the same operations as above to every element of the `markers` list. 
We will introduce `purrr` briefly here, but if you want more information and background, we recommend the [`purrr` cheatsheet (PDF)](https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf) and Jenny Bryan's great [`purrr` tutorial](https://jennybc.github.io/purrr-tutorial/index.html) you might want to look at.


The main functions in `purrr` are the `map()` functions, which take as their main arguments a **list** and a **function** to apply to each element of the list. 
The first one, `purrr::map()` is essentially equivalent to the `lapply()` function that is part of base R, but with some different defaults. 
We will use it to get the top rows from each table by applying the `head()` function to each element of the list.
The results are returned as a new list.

```{r head_markers, eval = FALSE}
purrr::map(
  as.list(markers), # select the first 3 clusters and convert to a 'regular' list for purrr
  head # the function to apply (note no parenthesis)
  )
```

This returns a list of data frames, which isn't quite what we want.

There is no built-in function that will give us just the first few _row names_, so we will have to define one, and `purrr` gives us a nice shorthand for doing that with `~` syntax.
In this syntax we type a `~` followed by an expression (R code) that uses `.x` as a placeholder for a single element of the list.
`purrr::map()` will then apply the expression to each element of the list, and return the results as a new list.

```{r head_markernames, live = TRUE}
# Get the first few row names of each table with a purrr function.
purrr::map(as.list(markers), # convert markers to a 'regular' list for purrr
           ~ rownames(head(.x))) # our custom function.
```

Another variant is `purrr::imap()`, which allows us to use the names of the list elements in our function. 
(Try `names(markers)` to see the names for the list we are working with now.)
We will use that here to name output files where we will print each of the marker tables, one for each cell type.
We are again defining a custom function within the call to `purrr:imap()` using the `~` syntax, but this time we can use `.x` for the list elements and `.y` for their names.
Because we don't know the identities of the clusters we identified, these are just the cluster numbers for now.

Making file names from numbers can be a a bit fraught, as we really want them to sort in numerical order, but many systems will sort by alphabetical order.
Unfortunately, that would tend to sort 10-19 before 2, 20-29 before 3, etc. 
To solve this, we are using the `sprintf()` function, which allows us to specify the format of a printed string.
In this case, we are using the signifier syntax of `%02d` to tell it that we will want to insert (`%`) a number (`d`), with two digits and leading zeros.
To see what this does a bit more simply, you might want try it out with the following command in the console: 
`sprintf("%02d", 1:10)`

In addition to writing the tables out, we are saving the data frames we created as a new list object that we can use in the next step.

```{r write_tables}
marker_df_list <- purrr::imap(
  as.list(markers), # convert markers to a 'regular' list for purrr
  ~ as.data.frame(.x) %>% # convert the table to a data frame
    tibble::rownames_to_column("gene") %>% # make genes a new column
    dplyr::arrange(FDR) %>% # sort to be sure small FDR are first
    readr::write_tsv( # write each data frame to a file
      file.path(marker_dir, # construct the output path
                sprintf("cluster%02d_markers.tsv", as.integer(.y)) # format cluster numbers in file names with leading zeros
                )
      )
  )
```

`purrr::map_df()` is another nice function in `purrr`. 
It applies the operations in the second argument and combines the output into a single data frame.
Optionally, it adds a column with the name specified by the `.id` argument to differentiate the rows that came from each element of the input list.

```{r top_markers, live = TRUE}
# Make a data frame of the top 20 markers for each cell type
top_markers <- purrr::map_df(marker_df_list,
                             head, 
                             n = 20,
                             .id = "cluster")
```

### Plotting marker gene expression

One thing we can do with this list of marker genes is to see how they look across the cells and clusters.
The `scater::plotReducedDim()` function makes this easy!
We have earlier colored points by some cell statistic, like the number of expressed genes, but it is just as easy to color by the expression of a single gene by using the gene identifier as the `colour_by` argument.

```{r marker_info, live = TRUE}
# get the top markers for cluster 1
gene_ids = top_markers %>%
  dplyr::filter(cluster == "1") %>%
  dplyr::pull(gene)

# look at the gene info for these
gene_info <- rowData(hodgkins_sce)[gene_ids, ]
data.frame(gene_info)
```


```{r plot_marker_expression}
rank <- 1
gene_id <- gene_info$ID[1]
symbol <- gene_info$Symbol[1]

plotReducedDim(hodgkins_sce, "UMAP", 
               colour_by = gene_id) + 
  guides(color = guide_colourbar(title = symbol))
```


## Next steps

So far we have identified clusters of cells (if you believe them), and found some genes that are associated with each cluster. 
What you might want to know at this point is what *cell types* comprise each cluster.
Setting aside the thorny question of "what is a cell type?", this is still a challenging problem!

One approach would be to look at the marker genes that we have defined, and explore whether they correspond to known pathways or biological processes from KEGG or Gene Ontology.
We will explore part of this approach in a later notebook.

In some situations, you might have a well-annotated data set with cells of each type that you are interested in. 
You could then compute some measure of similarity between the gene expression in your cells and the annotated cells, and then assign identity based on those measures.

One online tool is [Azimuth](https://azimuth.hubmapconsortium.org/) which uses [`Seurat`](https://satijalab.org/seurat/) under the hood, and will even allow you to download the R code to recreate the analysis it performs.


## Session Info

```{r session}
sessionInfo()
```
