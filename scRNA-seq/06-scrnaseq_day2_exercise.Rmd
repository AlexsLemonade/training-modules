---
title: "Single Cell Exercise: Day 2"
output:   
  html_notebook: 
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: inline
---

**CCDL 2020**

In this exercise notebook we will be using [*Tabula Muris* project](https://www.nature.com/articles/s41586-018-0590-4) data for dimension reduction for the cells of a mouse kidney sample, `10X_P7_0`. 

- Part A of this exercise is performing the quantification and processing of `10X_P7_0` with Alevin. 
- Part B of this exercise is performing dimension reduction on the quantified cells of `10X_P7_0`.

You are welcome to [skip to Part B](#part_b:_performing_dimension_reduction_on_10x_p7_0â€™s_cells) if you are not interested in performing the quantification steps with Alevin. 

# Part A: Quantifying single-cell expression of a liver sample.

In this part of the exercise we will be following the same steps for a tag-based scRNA-seq sample as we did in the `04-tag-based_scRNA-seq_processing.Rmd` notebook. 

**Relative workflow for tag-based data**
![](diagrams/tag-based_1.png)

## Checking your directories

While we are working from this `.Rmd` file, our current directory will automatically be `training-modules/scRNA-seq`, but you should check that your `Terminal` also is set to that directory.
Use the empty code chunk below to check your `p`resent `w`orking `d`irectory with `pwd`, and (on a different line) write out a command that would allow you to `l`i`s`t the files that are in the `tabula-muris` folder that is in `data`. 

When you think you've written the command correctly, copy and paste it into your Terminal window. 

```sh
# Copy and paste these commands in your Terminal and use `cd` to navigate to training-modules/scRNA-seq

```

You should see `fastq-raw` directory among other files we will use for this exercise. 

### Construct our Salmon Alevin quant command

To construct our `alevin` command, we'll walk through each option by itself to figure out what we should specify for it. 
After we've determined this for each option, we'll piece together the whole command. 

For determining what you will want to specify for each of these options, you may want to keep these items handy as reference: 
- [Alevin's documentation](https://salmon.readthedocs.io/en/latest/alevin.html) for more information on fragment library types.
- `04-tag-based_scRNA-seq_processing.Rmd` notebook where we performed pre-processing previously.

#### Library type: -l

For tag-based single cell, this `-l` for the library type will always be `ISR`.
Write down what this option line will look like here (but don't try to run it; it won't work):

```sh
# Write down what we will be using for our library specification, -l

```

#### Transcriptome index: -i

We will use the same transcriptome index we used in `04-tag-based_scRNA-seq_processing.Rmd`. 
This transcriptome index will need to be: 
- for mouse (`mm`) 
- made from a `cdna` genome
- be made with a `short` *-k*

This file path is admittedly odd so we will provide it to you here: 

```sh
# Here's the file path to the mouse cdna short transcriptome index already prepare for you
~/shared-data/reference/refgenie/mm10_cdna/salmon_index/short/short/
# This will be your -i option specification
```

To test if your file path is correct, use the `ls` command on the file path you wrote above, and the correct folder will have a `versionInfo.json` in it (among a lot of other files). 

```sh
# Use `ls` to see if your transcriptome index file path goes to a folder that seems legitimate

```

#### Input files: -1 and -2

For this exercise, we will be analyzing the data from sample `10X_P7_0`. 

In the case of tag-based data with alevin: 
`-1` option is for our `R1` file (contains CBs and UMIs)
`-2` option is for our `R2` file (contains the reads). 

Find the file path for the `10X_P7_0` `R1` fastq.gz file and write out what your `-1` specification will be.
We will only process one set of the files, the `_001` chunks so use the file path for that file only. (This chunk won't work if you try to run it due to permissions errors; no worries). 

```sh
# Write out the file path for 10X_P7_0's R1 FILE 001 file. 

# This will be your -1 option specification.
```

Now write out the file path for the `R2` file (it will be *almost* identical!). 

```sh
# Write out the file path for 10X_P7_0's R2 FILE 002 file. 

# This will be your -2 option specification.
```

In this `.Rmd` file we are using, we can make an `R` code chunk so we can use `file.exists()` to look for the files we just specified. 
Write out two `file.exists()` tests to check if both your `-1` and `-2` file paths lead to existing files. 
Copy and paste the file paths exactly so you don't accidentally introduce any typos to your tests. 
(*DO* run this code chunk). 

```{r files-exist, solution=TRUE}
# In this R code chunk, we can test if the file paths we specified above are legitimate by using `file.exist()` function.

# Use file.exists() to check for your R1 file 

# Use file.exists() to check for your R2 file 

```

You should get two `TRUE`s print out if you've correctly specified existing files. 

#### Output files: -o

We use `-o` to designate a folder for the output quant files. 
We will want to store the output in the `alevin-quant` folder, with its own folder named as `10X_P7_0`.

```sh
# Write out the file path to where we will want our alevin quantification results.

# This will be your -o option specification.
```

#### Transcript to gene file: --tgMap

We use `--tgMap` to supply a transcript to gene key that Alevin will use to quantify the genes.
This specification will go hand-in-hand with the transcriptome index you are using. 
In this case, we are using the same transcriptome index we used in `04-tag-based_scRNA-seq_processing.Rmd`; so we will also use the same transcript to gene key file as well. 
You'll find this file in the `data/tabula-muris` folder. 

```sh
# Write out the file path to the transcript-gene map file.

# This will be your --tgMap option specification.
```

#### Flags we'll need!

*--chromium*: Because we are using 10X Chromium data again, we need to use the `--chromium` flag in our command! (If we were using DropSeq data, we'd use a `--dropseq` flag instead of this).

*--dumpFeatures*: `alevinQC` depends on files that we get by using this option; so need this flag in our command as well!

### Put our Alevin command altogether and run it!

Remember that when we need a command to continue on to the next line, we end it with `\`. 

Here we've got a template of what your alevin quant command will look like. 
In the previous steps, we determined what each of these should be. 
Note that when we need a command to continue on to the next line, we end it with `\` (make sure there is no space after). 

**Template alevin command**
```sh
salmon alevin \
  -l <library_type> \
  -i <transcriptome_index_file_path> \
  -1 <R1_file_path> \
  -2 <R2_file_path> \
  -o <output_file_path> \
  --tgMap <tx2gene_file_path> \
  --<some_flag> \
  --<some_other_flag> \
  -p 5
```

First, copy and paste this whole template (but not the backticks) into the code chunk we have below. 
Then, it is your task to replace every `<fill_in_the_blank>` with what you determined previously! 

*Important tips as you fill in the blanks*:   
1) _Do_ remove the `<` and `>`'s. 
2) _Don't_ remove the `\`'s (and don't put a space at the end of the line with one). 
3) _Don't_ touch the `-p` command at the end. We have preset this for you - it determines how many [threads](https://en.wikipedia.org/wiki/Thread_(computing)) this command will be allowed. 

```sh
# Copy and paste this template alevin command here!
# Replace every `<fill_in_the_blank>` with what you determined previously. 

```

When you believe you have written in every option correctly, copy and paste the code chunk into your Terminal and press `Enter` to run it!

If you have specified everything correctly, the quantification will begin. 
This will take some time; when it is done the last message you will see is 

```
[alevinLog] [info] Finished optimizer
```

## Part B: Performing dimension reduction on 10X_P7_0's cells

In the second half of this exercise notebook, we will use the Alevin quantified data from sample `10X_P7_0` to perform dimension reduction on its cells. 

If you did _not_ complete Part A of this exercise notebook, you will need to use this command to copy over the results for `10X_P7_0` that we previously prepared for you. 

To copy over the full results (Part A only processed one of six pairs of fastq files), or if you did not complete part A, run this command:

```sh
cp -r ~/shared-data/training-data/tabula-muris/alevin/10X_P7_0 data/tabula-muris/alevin-quant/.
```

### Set up

We will be using `tximport` for reading in our Alevin quant data and the following packages: `ggplot2`, `scater`, `scran`, `magrittr` for normalization and visualization
Use this chunk to import these libraries (or you can choose to go the `::` route).

```{r libraries, solution=TRUE}
# Import the libraries specified, or from here on out, use the :: 

```

We'll also want to set the seed because there is some randomization involved in some of these steps!

```{r seed}
# Setting the seed for reproducibility
set.seed(12345)
```

### Read in the quantification file

First we will set up the paths to our Alevin output. 
The relevant file that `tximport` needs for our quantification output is called `quants_mat.gz`. 
The `quants_mat.gz` is in the `alevin` sub-directory of the output directory (``10X_P7_0`), which is automatically created by Alevin.
Call this file path object `quant_file`.

```{r solution=TRUE}
# Specify the file path to the `quants_mat.gz` file for 10X_P7_0 and call this object `quant_file`.

```

With our file path to `quants_mat.gz` specified, read it using the `tximport()` function, specifying the argument `type` as `"alevin"`.
You can reference [this example](https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Alevin). 
Call this new `tximport` object `txi`. 

```{r txi, solution=TRUE}
# Read in the `quant_file` using the `tximport::tximport()` function. 

```

For the next step, we will need to be able extract the `counts` part of the `txi` object.
Let's take a look at a preview of the `counts`. 
Hint: use a `$` to extract from the `txi` object. 

```{r peek-counts, eval = FALSE, solution=TRUE}
# Take a peek at the counts by extracting it from your `txi` object. 

```

### Create a SingleCellExperiment object

Let's turn our `tximport` object into a `SingleCellExperiment` object for downstream processing and call this object `sce`. 
To do this, we will use the `SingleCellExperiment::SingleCellExperiment()` function and supply it a `list()` that contains the `txi$counts` named `counts`. 

```{r sce-object, solution=TRUE}
# Create a SingleCellExperiment object by supplying a `list()

```

### Read in and set up the metadata

The metadata file for all the Tabula Muris samples, is called `TM_droplet_metadata.csv` in the `tabula-muris` folder. 
First we should specify the file path. 

```{r metadata-file, solution=TRUE}
# Specify the file path to the `TM_droplet_metadata.csv` file and call this object, `metadata_file`.
# Path to the metadata file 

```

Using the `metadata_file` object you just created, read in the file. 

```{r metadata, solution=TRUE}
# Read in the CSV file using the readr package

```

This metadata contains the information for all the samples, but we are only using `10X_P7_0` sample. 
Use the [`dplyr::filter`](https://dplyr.tidyverse.org/reference/filter.html) to reduce `metadata` to only the rows that correspond to `10X_P7_0` samples. 

```{r metadata-filter, solution=TRUE}
# Filter to 10X_P7_0 corresponding rows only (use the channel column). 

```

Note that our data in `sce` has cell barcodes in `colnames` (*e.g.*`CAGTCCTTCGGAGCAA`) but without the sample ids at the front end like is in our `metadata` (*e.g.* `10X_P7_0_CAGTCCTTCGGAGCAA`). 

```{r preview-colData}
# Preview the colData(sce)
head(colnames(sce))
```

We need to create a new column in `metadata` from the `cell` column where the `10X_P7_0_` part of the string is dropped. 
We highly recommend looking into the [stringr package](https://stringr.tidyverse.org/articles/stringr.html) functions when you encounter these types of problems. 

Here we have set up this step using [`str_replace()`](https://stringr.tidyverse.org/reference/str_replace.html) to replace all instances of `"10X_P7_0_"` with an empty string *e.g.* `""`. 

```{r cell_id-mutate, solution=TRUE}
# Creating a new column in `metadata` from the `cell` column where the `10X_P7_0_` part of the string is dropped. 

```

### Read in and set up mitochondrial genes

```{r mito-file-path, solution=TRUE}
# Specify file path to the `mm_mitochondrial_genes.tsv` file

```

Read in the mitochondrial TSV file with the `readr` package and name it `mito_genes`. 
Filter it only to the row names present in the `sce` object. 
Lastly, use `dplyr::pull()` to extract the `gene_id` column as a vector. 

```{r mito-genes, solution=TRUE}
# Read in the mitochondial genes TSV file using the readr package

  # Filter to the genes in that are included in `rownames(sce)` object

  # Use `dplyr::pull()` to extract the `gene_id` column

```

### Quality control filtering with scater

Use `scater::addPerCellQC()` to calculate our QC statistics including statistics for the subset of genes that are in our `mito_genes` vector. 
Store this back into `sce`. 

```{r calculateQC, solution=TRUE}
# Use scater::addPerCellQC where subsets are specified as a named list.

```

Let's make some plots of the QC data and use it to inform our next steps.
Create a data.frame from metadata for each cell (the `colData` for the `SingleCellExperiment` object.)

```{r cell_qc_df, solution=TRUE}
# Turn the `colData` for the `SingleCellExperiment` object into its own data.frame called `cell_qc_df`.

```

Use the `cell_qc_df` data frame we just created, to make some plots that can help you decide on cutoffs!
Your plots should help you decide what mitochondrial percentage cutoff is acceptable per cell. 

Plot the distribution of `subsets_mito_percent` as we did with the bladder data in the previous notebook. 
Why might the liver be different? Should we use the same cutoffs for our QC filter?

```{r plot-cell_qc_df, solution=TRUE}
# Plot the distribution of `subsets_mito_percent` from `cell_qc_df`

```

```{r plot2-cell_qc_df, solution=TRUE}
# Make a second plot with QC data from `cell_qc_df`

```

Using your QC and plots, create a subset of the `SingleCellExperiment` object, keeping only the columns (cells) that pass the thresholds you have chosen. 

```{r qc-pass, solution=TRUE}
# Create sce_filtered object with just the cells that pass your decided upon filters
# Construct a logical statement to determine which cells pass your QC filter for 

# Apply the filter to SCE filter

```

Calculate QC stats for the genes in the data set using `scater::addPerFeatureQC()` on your `sce_filtered`. 

```{r gene_qc}
# Calculate QC stats for your genes by using scater::addPerFeatureQC()
sce_filtered <- scater::addPerFeatureQC(sce_filtered)
```

Use the QC data (stored in `rowData` of your `sce_filtered`) to filter by row to only the genes. 
Decide upon a threshold for: 
- a minimum number of `detected` cells per gene
- a minimum mean `expression` count per gene
You an use `>5` cells and `> 0.1` mean expression if you wish. 

Filter `sce_filtered` by only including those genes that are `TRUE` for both the minimum thresholds. 

```{r gene-filter, solution=TRUE}
# Create a logical expression for the minimum number of detected cells per gene

# Filter the rows (genes) by those that are TRUE for both the minimum thresholds (hint use &)

```

### Normalize the data

Perform the same normalization steps using `scran::computeSumFactors()` and `scater::logNormCounts()` as we did in the `05-dimension_reduction_scRNA-seq.Rmd` notebook. 

First cluster similar cells using `scran::quickCluster()`. 

```{r qclust, solution = TRUE}
# Cluster similar cells using `scran::quickCluster()`

```

Use `scran::computeSumFactors()` to calculate the the sum factors so we can use them to normalize the data in the next step. 
You will need to specify the `clusters` argument as the object you obtained from `scran::quickCluster()` that you performed in the last step. 

```{r computeSumFactors, solution = TRUE}
# Compute sum factors for each cell cluster grouping for sce_filtered using the `scran::quickCluster()` you performed. 

```

Normalize and log transform using `scater::logNormCounts()` now that you have calculated the the sum factors (those will be store in the `sce_filtered` object).

```{r normalize, solution=TRUE}
# Normalize and log transform. 

```

![**Status of the current dataset**](diagrams/tag-based_3.png)

### Perform dimension reduction!

Use what you have learned about `ggplot2` visualizations and create dimension reduction plots using these functions: 

- `scater::calculatePCA()`
- `scater::calculateUMAP()`
- `scater::calculateTSNE()`

We recommend using multiple dimension reduction strategies since each have their own strengths and drawbacks. 
We will take you through the steps for PCA, but you can generally repeat these steps for each dimension reduction strategy but you'll have to determine what changes are needed on your own. 
Feel free to make the plots your own. 
You may want to Google `ggplot2` ideas for inspiration or take a look at the [ggplot2 cheatsheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) for reference. 

_Step 1)_ Calculate the dimension reduction. 

```{r calculate-dr, solution=TRUE}
# Calculate on your normalized `sce_filtered` object

```

_Step 2)_ Prepare for plotting by combining the dimension reduction calculations with the metadata. 
Perform a `dplyr::left_join()` with `tm_pca` and `metadata`. 
Here a `left_join()` with `tm_pca` on the left will still keep the data on the left and leave `NA`s where/if there is no associated metadata. 

```{r add-metadata, solution=TRUE}
# Combine your dimension reduction results with the metadata

  # You will need to use as.data.frame() to turn tm_pca into a data.frame instead of a DataFrame. 

  # You will also need to use tibble::rownames_to_column()

  # Perform a dplyr::left_join() with the metdata

```

_Step 3)_ Plot the dimension reduction and using what you have learned about ggplot2. 

```{r plot-pca, solution=TRUE}
# Plot reduced dimensionality components using ggplot2. Specify a color label if desired! 

```

Use `ggplot2::ggsave()` to save your plot to the `plots` directory. 

```{r ggsave, solution = TRUE}
# Save your plot with ggsave()

```

Now you can repeat these general steps for the other dimension reduction strategy! 
Another idea is using these visualizations to compare unnormalized and normalized versions of your data.

## Session Info

```{r sessioninfo}
sessionInfo()
```
