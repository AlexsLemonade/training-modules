---
title: "Importing, processing, and exploring Visium data"
author: Data Lab for ALSF
date: 2026
output:
  html_notebook:
    toc: true
    toc_float: true
---

## Objectives

- Read Visium data into R
- Filter to spots overlapping tissue
- Calculate quality control measures on spatial transcriptomic data
- Remove likely low-quality spots with `SpotSweeper()`
- Normalize spatial expression data
- Visualize spatial transcriptomic data 

## Introduction

In this notebook, we'll learn some basic import, processing, and visualization of a Visium data set, starting with the Space Ranger output. 

The data we'll use in this notebook is from an anaplastic Wilms Tumor sample in the [Single-cell Pediatric Cancer Atlas](https://scpca.alexslemonade.org/projects/SCPCP000006).
This sample was processed using first-generation 3' Visium technology, and it was quantified with `Space Ranger 1.3.1`.

## Set up

To begin, we'll load the core library for spatial transcriptomic objects in Bioconductor, `SpatialExperiment`.
We won't be doing any calculations involving random numbers here, so we don't need to set a seed.

```{r libraries}
# Load libraries

# The main class we use for spatial transcriptomic data
library(SpatialExperiment)

# To support plotting
library(patchwork)

# Set ggplot2 theme
ggplot2::theme_set(ggplot2::theme_bw())
```

### Directories and files

Next we'll define paths and files.

```{r inputs, live=TRUE}
# define sample id we'll be analyzing 
sample_id <- "SCPCS000190"

# main data directory for this sample
data_dir <- file.path("data/wilms-tumor", sample_id)

# Path to Space Ranger output
raw_spaceranger_dir <- file.path(data_dir, "outs")

# reference data directory
ref_dir <- file.path("data/reference")

# Path to mitochondrial genes table
mito_file <- file.path(ref_dir, "hs_mitochondrial_genes.tsv")
```


```{r outputs}
# Directory and file to save output
normalized_dir <- file.path(data_dir, "normalized")

# create the directory if it does not exist
fs::dir_create(normalized_dir)

# output RDS file for normalized Spatial Experiment (SPE) object
output_spe_file <- file.path(
  normalized_dir,
  "SCPCS000190_normalized.rds"
)
```



## Reading Space Ranger data

We'll use the `VisiumIO` package to read this data in.
The directory structure typically looks something like this, with differences for different technology versions.

```markdown
_add file tree here with standard visium output_
```

Let's see what we have:

```{r dir-spaceranger, live = TRUE}
dir(raw_spaceranger_dir)
```

The filtered/raw matrix directories are analogous to we'd get from `Cell Ranger` for single-cell sequencing, but the `spatial` directory contains spatial information, including images, that augment the data with its full spatial context.
Without this directory, we could still read in the filtered/raw and make an `SCE`, but you wouldn't have the spatial info.

Along those lines, let's have a closer look at what's in the `spatial` directory:

```{r dir-spatial, live = TRUE}
dir(
  file.path(raw_spaceranger_dir, "spatial")
)
```

Placeholder to describe each image file:

- `"aligned_fiducials.jpg"`
- `"detected_tissue_image.jpg"` 
- `"tissue_hires_image.png"` 
- `"tissue_lowres_image.png"`
- `"tissue_positions_list.csv"`
- `"scalefactors_json.json"`   

It's worth mentioning that this is a slightly older technology than the current Visium `CytAssist` image, which means there is no specific `Cytassist` image.
This won't affect our analysis, but worth noting when reading in since by default the functions assume that image is present. 


We'll import the raw, not filtered, version of the data here so that we can see full processing steps and save it to a variable called `spe`, using the package `VisiumIO`.

```{r import-visium, live = TRUE}
# path to quantified RNA 10X output
rna_dir <- file.path(raw_spaceranger_dir, "raw_feature_bc_matrix")

# path to spatial 10X output
spatial_dir <- file.path(raw_spaceranger_dir, "spatial")

spe <- VisiumIO::import(
  VisiumIO::TENxVisium(
    # path that contains the sequencing data
    resources = rna_dir,
    # path that contains the spatial data
    spatialResource = spatial_dir,
    # which image(s) to import - use lowres to save some memory/space
    # we also need to override the default since it assumes there is a CytAssist image
    images = "lowres"
  )
)

# print the spe
spe
```

Let's get to know our `SPE` object!
It's essentially an `SCE`, but with a few more bells and whistles.
This means there are some functions we'll use to explore it that you might recognize, but there will also be some new ones only used for `SPE` objects.

First, note that we have 4992 spots - this is not a random value.
It's the number of spots on a Visium 6.5 x 6.5 slide. 

Like `SCE`s, we have slots like `assays` for count matrices, `rowData` for feature metadata, and `colData` for _spot_ metadata - recall, our experimental units are not individual cells in spatial transcriptomics.
Let's take a tour:

```{r spe-rowdata}
rowData(spe)
```

```{r spe-assays}
counts(spe)[1:10, 1:10]
```
Again, for the colData`, we're looking at spots and not cells.
With this technology, where each spot is 55 Âµm, we can expect there's somewhere between 1-10 cells per spot.

```{r spe-coldata, live = TRUE}
colData(spe)
```
Check out that `in_tissue` column.
It contains 0/1 because we read in the raw `Space Ranger` output, which includes all spots including those which don't actually overlap tissue.
Ultimately, we won't want to analyze the spots that are not on top of tissue, so we'll have to deal with that.

Unlike `SCE`s, we have spatial information in a dedicated `spatialCoords` slot which contains the x/y coordinates on the slide:
```{r spe-spatialcoords, live = TRUE}
# handy function from our code package SpatialExperiment
# literally is giving x/y coordinates
spatialCoords(spe) |> head()
```

We also have a slot that just holds the images, `imgData`, although looking at it directly isn't very interesting.
But, this stored information will help us make figures!

```{r spe-imgdata, live = TRUE}
imgData(spe)
```

### Introduction to spatial data visualization

Before we get further, let's go ahead and actually look at our data.
Because the spatial and image information is contained in the object, we can plot directly from this object using the viz package [`ggspavis`](https://bioconductor.posit.co/packages/release/bioc/vignettes/ggspavis/inst/doc/ggspavis_overview.html).


```{r plot-visium, live = TRUE}
#| fig.width: 7

ggspavis::plotVisium(spe)
```

Here, we see the spots overlaid on the slide as well as slide boundaries.
You'll notice that every single spot is shown, including ones that don't overlap tissue directly - indeed, all 4992 spots are present in the `SPE` right now!

By default this shows the spots, but we can hide them and zoom into the tissue on the slide.
This is a helpful way to pop up the H&E for side-by-side comparisons with other plots you might make.

```{r plot-visium-zoom, live = TRUE}
#| fig.width: 5

ggspavis::plotVisium(
  spe, 
  spots = FALSE, # don't show the spots
  zoom = TRUE    # zoom into the slide area
) 
```

TODO: save this text for when we actually plot genes?
Let's take a moment to chat about Wilms Tumor - these tumors in the developing kidney are often composed of a couple histologic compartments, blastemal, stromal (with mesenchymal biology), and sometimes epithelial components.
In this tissue section, we can see two major components: the bluer indicating densely cellular, ECM-poor regions consistent with blastema, and paler pink regions consistent with stromal tissue.


There's another function in `ggspavis` called `plotCoords` which hides the H&E to just show the spots; this plot is not currently very compelling without any colors, but we'll add those soon!

```{r plot-coords, live = TRUE}
#| fig.width: 7

# plot just the spots
ggspavis::plotCoords(spe) 
```

The spot layout looks a bit different.
By default, this function will only plot spots that overlay tissue, even if those spots are still in the `SPE`.

We can override this if we want, but really what we want to do is actually remove those spots since they are entirely uninformative - we'll do this in the next section.


## Filtering empty spots

We only care about spots on top of tissue, so let's begin by removing the `in_tissue = 0` spots.
Note that if we had read in the `filtered_feature_bc_matrix` instead, the data would already be filtered to only `1` in this column, but we need to take this step because we read in the `raw`. 
We can make a rough analogy, that this analysis step is like filtering empty droplets to retain only droplets with cells in scRNA-seq, but here we're retaining only spots over tissue.

We can visualize which spots those are, and we'll do it over the H&E to clearly see the relationship.
We'll use the `annotate` argument, but `plotVisium` sees that this column is an integer and forces it to use a continuous color scale; we'll go ahead and make it a factor version of it to plot with.

```{r plot_in_tissue}
#| fig.width: 7

# make a factor version of this column to plot with, specifying "No" and "Yes" plot labels
spe$in_tissue_factor <- factor(spe$in_tissue, levels = c(0, 1), labels = c("No", "Yes"))

ggspavis::plotVisium(
  spe, 
  annotate = "in_tissue_factor", 
  # specify a custom palette
  pal = c("Yes" = "yellow", "No" = "red")
) +
  # use ggplot2::guides() to override legend titles in ggspavis
  ggplot2::guides(
    fill = ggplot2::guide_legend(
      title = "Spot overlaps tissue", 
      override.aes = list(size = 2)
    )
  )
```

- The purple tissue overhang on the left isn't colored at all - indeed, there aren't spots at those coordinates outside the slide
- Red points are those to filter out - they are uninformative since they don't overlap tissue.

```{r filter_in_tissue, live = TRUE}
# keep only spots that are in the tissue and save to filtered_spe
filtered_spe <- spe[, spe$in_tissue == 1]

# print resulting filtered_spe
filtered_spe
```


Now, we're down to 4120 spots from the original 4992, but that's still a pretty good amount. 
But not all of these spots are necessarily good quality, so we'll want to do some additional QC filtering next.

## Filtering low-quality spots

### Filtering with global QC thresholds

As a first step towards filtering, we can borrow some approaches from scRNA-seq and calculate some quality-control measures. 
Let's do that and have a look - we'll get our mitochondrial genes for QC calculations and we'll use `scran::addPerCellQC()` like we might for single-cell (except here it adds per spot).

```{r get mitochondrial genes}
# read in a table of mitochondrial genes and extract ids
mito_genes <- readr::read_tsv(mito_file) |>
  # filter to only the genes that are found in our dataset
  dplyr::filter(gene_id %in% rownames(filtered_spe)) |>
  # create a vector from the gene_id column
  dplyr::pull(gene_id)
```

```{r calculate qc, live = TRUE}
filtered_spe <- scuttle::addPerCellQC(
  filtered_spe,
  subsets = list(mito = mito_genes)
)

# print resulting colData to see QC stats
colData(filtered_spe) |> head()
```

`ggspavis` comes with a helpful QC plotter (makes histograms by default but has a couple more options!).
These are `ggplot2` objects, so we can use `ggplot2` code with them like add a title to each.

```{r global qc distributions}
#| fig.width: 12
#| fig.height: 4

# Extract the colData into a data frame for plotting
coldata_df <- colData(filtered_spe) |>
  as.data.frame() |>
  # relocate barcodes to an actual column instead of rownames
  tibble::rownames_to_column("barcode") 

# Define density plots for each statistic
qc_plot_sum <- ggplot2::ggplot(coldata_df) + 
  ggplot2::aes(x = sum) + 
  ggplot2::geom_density(fill = "lightblue") +
  ggplot2::labs(title = "Total unique UMIs")

qc_plot_detected <- ggplot2::ggplot(coldata_df) + 
  ggplot2::aes(x = detected) + 
  ggplot2::geom_density(fill = "steelblue") +
  ggplot2::labs(title = "Total detected genes")

qc_plot_mito <- ggplot2::ggplot(coldata_df) + 
  ggplot2::aes(x = subsets_mito_percent) + 
  ggplot2::geom_density(fill = "slateblue") +
  ggplot2::labs(title = "Mitochondrial %")


# Plot together with patchwork
qc_plot_sum + qc_plot_detected + qc_plot_mito
```

These distributions all look unimodal without too much skew, which is different from how distributions from single-cell data might look. 

Placeholder for discussion about differences/similarities in technical artifacts between data types:

- One of the reasons we filter on these metrics in single cell is due to potential differences in cell capture across droplets
- This isn't a factor in spatial where QC stats are calculated per spot aka for aggregates of cells, extremes end up getting smoothed out
  - Differences in capture aren't due to heterogeneity from droplet capture but because of tissue biology/prep:
  - We have distinct regions of tissue or groups of cells that have less genes detected than other ones (biology) or because the tissue didn't lay on the slide completely flat or wasn't completely permeabilized in all spots equally

For example, let's consider the mitochondria percent distribution:

- We do see a long right-tail for mitochondrial percentages, but the values are all really low which doesn't suggest any major quality issues.
- The lower values here vs in single-cell data make sense because cells weren't stressed in the same way they would be for single-cell library prep; more likely to tell you about the tissue quality itself (biology) and not spot quality (technical) 

Let's plot the same stats on the slide.
We'll include the H&E plot here as well for an immediate comparison.

```{r global qc coords}
#| message: FALSE
#| fig.width: 10

he_plot <- ggspavis::plotVisium(filtered_spe, spots = FALSE, zoom = TRUE) +
  ggplot2::ggtitle("H&E") +
  # add styling to match other panels
  ggplot2::theme(
    plot.title = ggplot2::element_text(
      hjust = 0.5, 
      margin = ggplot2::margin(0, 0, 0.1, 0)
    ),
    panel.border = ggplot2::element_rect(color = "black", linewidth = 0.25)
  )

qc_spots_sum <- ggspavis::plotCoords(filtered_spe, annotate="sum", point_size = 1) + 
  # use distinct palette
  ggplot2::scale_color_distiller(palette = "Blues", direction = 1) +
  ggplot2::ggtitle("Total unique UMIs")

qc_spots_detected <- ggspavis::plotCoords(filtered_spe, annotate="detected", point_size = 1) + 
  # use distinct palette
  ggplot2::scale_color_distiller(palette = "YlOrRd", direction = 1) +
  ggplot2::ggtitle("Total detected genes")

qc_spots_mito <- ggspavis::plotCoords(filtered_spe, annotate="subsets_mito_percent", point_size = 1) + 
  # use distinct palette
  ggplot2::scale_color_distiller(palette = "Greens", direction = 1) +
  ggplot2::ggtitle("Mitochondrial %")

# wrap plots with patchwork into 2x2 grid
patchwork::wrap_plots(
  he_plot, 
  qc_spots_sum, 
  qc_spots_detected, 
  qc_spots_mito, 
  nrow = 2
)
```

Now, we start to see there's more to the story.
There is spatial heterogeneity in these QC stats:

- the likely stromal regions have distinctly higher mitochondrial percentages (although again, these values are pretty low all around!) and fewer detected UMIs/genes
- the likely blastema regions tend to have more detected UMIs/genes

This tells us that there is local structure in the data that we might like our QC approach to take into consideration.
Using these global thresholds, we can see that QC is confounded by biology. 
If we filter these spots, we'll be removing spots associated with a particular tissue region.
This shows that global thresholds may not be suitable for data with this kind of heterogeneity, so a different approach could be warranted.
Worth noting, this is not strictly a spatial transcriptomics issue; there can be quite a bit of heterogeneity in scRNA-seq data too depending on what was sequenced!
Always plot your data!

### Filtering with local QC thresholds

Rather than finding outliers based on overall QC stats derived across biologically distinct domains/tissue regions, we can instead look for _local_ outliers to filter, i.e. spots with properties that deviate from their neighborhood of nearby spots.
Placeholder text to introduce [`SpotSweeper`](https://www.bioconductor.org/packages/3.22/bioc/vignettes/SpotSweeper/inst/doc/getting_started.html):

- Evaluates spots relative to their local neighborhood which is defined with `kNN`
- Calculates local means and variances of standard QC metrics to flag outliers for removal within a local tissue context
- Can be used to find both individual outlying spots as well as so-called "hangnails" which are regional artifacts caused by e.g. issues in tissue prep or other technical issues
  - Note that hangnail detection is performed using variance in mitochondrial percentages. 
  Since our values for mitochondrial percentage are very low with minimal variance, hangnail detection won't be relevant for us here

We'll detect local outliers based using `SpotSweeper::localOutliers()` which takes these arguments:

- `metric`: name of column in `colData` with QC stat of interest
- `direction`: are lower value or higher value outliers bad?
  - e.g. we'd say "lower" for detected (we don't want low detected values), and we'd say "higher" for mitochondrial percentage
- `n_neighbors`: number of neighbors for building the `kNN` graph; Default is 36
- `log`: whether to consider the `log1p` of the metric; Default is `FALSE`
  - The method assumes a normal distribution, so logging a metric may be needed to meet assumptions
  - logging "detected" and "sum" is often recommended because these distributions are unbounded and span orders of magnitude
  - logging "mitochondrial" is not often recommended because it's bounded `[0,100]` and logging percentages can distort the distribution
- `cutoff`: Threshold for identifying outliers; Default is 3, meaning 3 standard deviations from the mean (think z-scores)
  - Can make this lower to be more strict (more spots will get removed), lower to be less strict (more tolerant of outliers), but don't go too high or low or you're not really detecting outliers anymore
- `workers`: Number of cores for parallel processing; Default is 1

This function returns an `SPE` object with added `colData` columns we can use to find all the local outliers.

Let's start off by looking for library size ("sum" column) outliers:

```{r spotsweeper-sum, live = TRUE}
# specify defaults for sum to be explicit
filtered_spe <- SpotSweeper::localOutliers(
  filtered_spe, 
  metric = "sum", 
  direction = "lower", 
  n_neighbors = 36, 
  log = TRUE,
  cutoff = 3
)
```


What do we have now?

```{r coldata-spotsweeper-sum, live = TRUE}
colData(filtered_spe)
```
New columns include:

- `sum_log`: The `log1p()` (i.e., `log(x+1)`) of the `sum` column
- `sum_outliers`: Logical whether or not the spot is an outlier
- `sum_z`: The _local_ z-score for `sum_log`, among spots in the local neighborhood.
  - 0: same as neighbors on average
  - high positive value: much higher `sum` than neighbors
  - low negative value: much lower `sum` than neighbors, which in this case would be the ones to filter
  
Let's see some of this relationship - we'll plot `sum_log` (log of a globally-calculated stat) against `sum_z` (stat for _local_ outlier), with a guiding line for the cutoff.

```{r sum_log_z_plot}
filtered_spe_coldata <- colData(filtered_spe) |>
  as.data.frame()

ggplot2::ggplot(filtered_spe_coldata) + 
  ggplot2::aes(
    x = sum_log,
    y = sum_z,
    color = sum_outliers
  ) +
  ggplot2::geom_point(alpha = 0.5) + 
  # add guiding line at outlier cutoff
  ggplot2::geom_hline(yintercept = -3, color = "blue")
```

Based on this metric, most spots are not outliers, and while most are fairly close to the 3 cutoff, several are are more extreme outliers!
We also gain some insight about how global vs local filtering would play out.
Let's imagine we did global filtering with a threshold of 500, whose log is 6.21.
Looking at the x-axis here, that means we would only have removed three spots.
But with local filtering, we are catching additional spots that deviate from their local neighborhood and filtering a few more out, but on the whole this dataset seems to be fairly good quality so it's not a ton.

Let's plot this next to the H&E:
We'll use a plotting function from `SpotSweeper`, `SpotSweeper::plotQCmetrics()`, which will allow us to both color by a statistic and highlight outlier points.
Well plot the `sum_log` side-by-side with `sum_z` to compare.

Tip!
When using this function, the point color is a "fill" aesthetic (which can be customized), and the point outline is a "color" aesthetic (the color of which is quite finicky to customize so we'll leave that alone, but we can customize its `linewidth` parameter).

```{r spotsweeper-plotqc-sum, live = TRUE}
#| fig.width: 10
#| message: FALSE

sum_log_plot <- SpotSweeper::plotQCmetrics(
  filtered_spe, 
  metric = "sum_log", # how to *fill* spots
  outliers = "sum_outliers", # which spots to *color* with an outline
  stroke = 0.75 # size of outline
) +
  # customize the palette for filling spots
  ggplot2::scale_fill_distiller(palette = "Blues") +
  ggplot2::ggtitle("Log of total UMI")


sum_z_plot <- SpotSweeper::plotQCmetrics(
  filtered_spe, 
  metric = "sum_z", # how to *fill* spots
  outliers = "sum_outliers", # which spots to *color* with an outline
  stroke = 0.75 # size of outline

) +
  ggplot2::scale_fill_viridis_c() +
  ggplot2::ggtitle("Local z-score for total UMI")

sum_log_plot + sum_z_plot
```
Here, we can see how spots are distributed across the slide.
Are there spots you would expect to be flagged for filtering based on the `sum_log` plot?
Are there spots you might not have expected to be filtered based on the `sum_log` plot?

One key parameter that this relies on is the "neighborhood size" (`n_neighbors` argument).
How would this have changed if we shifted the neighborhood size?
To not clutter up our existing object, we'll save to new objects and plot as a exploration to learn about neighborhood size.

```{r spotsweeper-compare-k}
#| fig.width: 10
#| message: FALSE

# Detect outliers with a large neighborhood and make associated plot
filtered_spe_n100 <- SpotSweeper::localOutliers(
  filtered_spe, 
  metric = "sum", 
  direction = "lower", 
  n_neighbors = 100
)
outlier_plot_n100 <- SpotSweeper::plotQCmetrics(
  filtered_spe_n100, 
  metric = "sum_log",
  outliers = "sum_outliers", 
  stroke = 0.75 
) +
  ggplot2::scale_fill_viridis_c() +
  ggplot2::ggtitle("neighborhood k = 100")


# Detect outliers with a small neighborhood and make associated plot
filtered_spe_n10 <- SpotSweeper::localOutliers(
  filtered_spe, 
  metric = "sum", 
  direction = "lower", 
  n_neighbors = 10
)
outlier_plot_n10 <- SpotSweeper::plotQCmetrics(
  filtered_spe_n10, 
  metric = "sum_log",
  outliers = "sum_outliers",
  stroke = 0.75 
) +
  ggplot2::scale_fill_viridis_c() +
  ggplot2::ggtitle("neighborhood k = 10")


# Plot outliers detected with different neighborhood sizes
outlier_plot_n100 + outlier_plot_n10
```
There's definitely some overlap, but also spots that are only filtered out for one of these neighborhood sizes.
In particular, the spot on the top left: With a large neighborhood, its low value is an outlier, but with a small neighborhood it is not and outlier because the immediately surrounding spots are also lower.


**TODO: too many scatterplots probably, anyone have a preference?**

We can also see some of these differences with scatterplots:

```{r neighborhood-size-scatterplots}
#| fig.width: 10
#| fig.height: 5

# Extract data frames for each object
n100_spe <- colData(filtered_spe_n100) |>
  as.data.frame()
n10_spe <- colData(filtered_spe_n10) |>
  as.data.frame()

# Plot sum_z against sum_log for each object
scatter_n100 <- ggplot2::ggplot(n100_spe) + 
  ggplot2::aes(
    x = sum_log,
    y = sum_z,
    color = sum_outliers
  ) +
  ggplot2::geom_point(alpha = 0.5) + 
  ggplot2::geom_hline(yintercept = -3, color = "red") + 
  ggplot2::ggtitle("n_neighbors = 100")


scatter_n10 <- ggplot2::ggplot(n10_spe) + 
  ggplot2::aes(
    x = sum_log,
    y = sum_z,
    color = sum_outliers
  ) +
  ggplot2::geom_point(alpha = 0.5) + 
  ggplot2::geom_hline(yintercept = -3, color = "red") + 
  ggplot2::ggtitle("n_neighbors = 10")

# Plot together with patchwork, with a single shared legend
scatter_n100 + scatter_n10 + patchwork::plot_layout(guides = "collect")
```

We can also compares the z-scores directly:

```{r sum-z-scatterplot}
compare_z_df <- data.frame(
    n100 = n100_spe$sum_z, 
    n10 = n10_spe$sum_z, 
    sum_log = n10_spe$sum_log
  )

ggplot2::ggplot(compare_z_df) + 
  ggplot2::aes(x = n100, y = n10, color = sum_log) +
  ggplot2::geom_point(alpha = 0.5) + 
  ggplot2::labs(
    x = "n_neighbors = 100", 
    y = "n_neighbors = 10", 
    title = "sum_z scores"
  ) + 
  ggplot2::geom_hline(yintercept = -3, color = "red") +
  ggplot2::geom_vline(xintercept = -3, color = "red") +
  ggplot2::theme(aspect.ratio = 1)
```
The top right quadrant shows spots that both neighborhood sizes retain, and the bottom left quadrant shows spots that both neighborhood sizes will filter out.
The top left shows spots that will only be filtered out for `n_neighbors = 100`, and the bottom right shows spots that will only be filtered out for `n_neighbors = 10`.


The point is, changing the cutoff or changing the neighborhood size will influence which spots are flagged for removal - plot your data!
If you have specific biological intuition about how much variation you expect in the tissue, you might want to use that to inform cutoffs and the neighborhood size, and it's ok to explore.


Let's get back on track: let's do the same outlier detection for `detected` and `subsets_mito_percent`, and we'll proceed with the default cutoff of 3 with the default neighborhood size of 36.


```{r spotsweeper-detected, live = TRUE}
#| fig.width: 7

# Calculate local outliers for the `detected` metric
filtered_spe <- SpotSweeper::localOutliers(
  filtered_spe, 
  metric = "detected", 
  direction = "lower"
)

# Plot the slide showing outliers
SpotSweeper::plotQCmetrics(
  filtered_spe, 
  metric = "detected_log",
  outliers = "detected_outliers", 
  stroke = 0.75
) +
  ggplot2::scale_fill_viridis_c()
```


```{r spotsweeper-mito, live = TRUE}
#| fig.width: 7

# Calculate local outliers for the `subsets_mito_percent` metric
filtered_spe <- SpotSweeper::localOutliers(
  filtered_spe, 
  metric = "subsets_mito_percent", 
  direction = "higher", # we want to remove HIGHER values 
  log = FALSE, # don't log
  cutoff = 3
)

# Plot the slide showing outliers
SpotSweeper::plotQCmetrics(
  filtered_spe, 
  metric = "subsets_mito_percent",
  outliers = "subsets_mito_percent_outliers", 
  stroke = 0.75
) +
  # switch palette direction to make outliers are darker colors, matching other plots
  ggplot2::scale_fill_viridis_c(direction = -1)
```
Even though mitochondrial percentages are fairly low across all spots, this approach helps us find spots that are abberantly low within their neighborhood, all of which we would miss with global filtering (where we might pick a threshold of 15-25% for single-cell data).


Now that we've calculated all this, how many of each kind of outlier are there?

```{r count-local-outliers}
# Prepare data frame to count outliers
outliers_df <- colData(filtered_spe) |>
  as.data.frame() |>
  dplyr::select(ends_with("_outliers"))

# Count total outliers for each metric: The total TRUE values in the `sum_` columns
outliers_df |>
  dplyr::summarize(
    sum_outlier_count = sum(sum_outliers),
    detected_outlier_count = sum(detected_outliers),
    mito_outlier_count = sum(subsets_mito_percent_outliers)
  )
```

Let's visualize how these outliers relate to one another with a proportional Venn Diagram, using the `eulerr` package to help us:

```{r outliers-venn-diagram}
eulerr_data <- outliers_df |>
  # reorder & rename columns columns for display
  dplyr::select(
    mito_percent = subsets_mito_percent_outliers, 
    detected = detected_outliers, 
    sum = sum_outliers
  ) |>
  # venn diagram calculations
  eulerr::euler()

plot(
  eulerr_data, 
  quantities = TRUE, 
  legend = TRUE,
  labels = TRUE,
  fills = c("#F0E442", "#56B4E9", "#009E73")
)
```

Let's go ahead and filter all these spots out:

```{r build-local-filter}
# combine all outliers into "local_outliers" column to filter on
filtered_spe$local_outliers <- filtered_spe$sum_outliers |
  filtered_spe$detected_outliers |
  filtered_spe$subsets_mito_percent_outliers
```


```{r perform-local-filter, live = TRUE}
# keep only spots where `local_outliers` is FALSE
filtered_spe <- filtered_spe[, filtered_spe$local_outliers == FALSE]

# print resulting SPE
filtered_spe
```

From the full set of 4992 spots, we are left with 4149 spots that both overlap tissue and don't have obvious quality issues. 


## Normalization

## Exploring marker gene expression


## Session info

To conclude, we'll run the `sessionInfo()` command to print out exactly what system setting and R package versions were used to run this code.

```{r}
sessionInfo()
```

