---
title: "Intro to Tidyverse"
output:   
  html_notebook: 
    toc: true
    toc_float: true
---

**CCDL 2019**

In this notebook, we will take you through the basics of the tidyverse: 
a collection of packages that make R easier to use and more convenient.  

We recommend using the free books Hadley Wickham and friends have on 
how to use the [tidyverse packages](https://r4ds.had.co.nz/index.html).

## Set Up

R packages are collections of functions. 
Installing R on your computer installs `base` functions like statistical tests 
and some plotting functionality.
The `tidyverse` is a collection of packages that are handy for general data 
wrangling, analysis, and visualization. 
Other packages that are specifically handy for different biological analyses are 
found on [Bioconductor](https://www.bioconductor.org/).
If we want to use a package's functions we first need to install them.
In our Docker container, we already have `tidyverse` and other packages we will
use in this workshop installed for you. 
But if you needed to install it or other packages available on CRAN, you 
do it using the `install.packages` function like this: `install.packages("tidyverse")`

```{r Load tidyverse}
library(tidyverse)
```

### Referencing a library's function with `::`

Note that if we had not imported the tidyverse set of packages using `library` 
like above, and we were using a tidyverse function like `read_tsv`, we would need to 
tell R what package to find this function in.
To do this, we would use `::` to tell R to load in this function from the 
`readr` package by using `readr::read_tsv`.
You will see this `::` method of referencing libraries throughout the course.  

## About directories

Before we can import the file we need, we should double check where R is 
looking for files aka our what our *working* directory currently is. 
We can do this by using the `getwd()` function, which will tell us what folder
we are in. 

```{r}
# Let's check what directory we are in:
getwd()
```

Note that for Rmd files, the working directory is always wherever the file is 
located. 
We can use the `dir()` function to have R list the files in our working 
directory. 

```{r}
# Let's check what files are here
dir()
```

#### Read a TSV file

What we should see is the file `metadata.tsv` show up as one of the files when 
we run `dir()`.
If for some reason we were not in the correct directory, we can either set our
directory to somewhere else using `setwd()` OR we can tell R to look for the 
file `metadata.tsv` somewhere else using a relative `file.path()` (more on this
later in this notebook).

We will use this `metadata.tsv` file for our examples here.
This metadata is from GSE30074 on [refine.bio](https://www.refine.bio/experiments/GSE30074/expression-data-from-30-medulloblastomas),
a gene expression dataset from medulloblastoma ([Park et al. _Neuro Oncol._ 2011.](https://www.ncbi.nlm.nih.gov/pubmed/22090452)).
  
First let's read in the dataset using the tidyverse package: `readr`.
Although base R has read-in functions, the `readr` functions are faster and more
straightforward to use so we are going to use those here. 
Because the file we are reading in is a TSV file we will be using the 
`read_tsv` function. 
But note that there are analogous functions for CSV files (`read_csv`) and 
other files types.

```{r}
# The file we are reading in is our argument for read_tsv
metadata <- read_tsv("metadata.tsv")
```

#### Managing directories

To keep our files organized, we will want to make a directory for our output. 
We will call this directory: `results`. 
But before we create the directory, we should check if it already exists. 
Let's use the `dir.exists` function to see if a `results` directory already 
exists in our working directory. 

```{r}
# Check if the results directory exists
dir.exists("results")
```

If the above says `FALSE` that means we will need to create a `results` directory
using the function `dir.create`.

```{r}
# Make a directory within the working directory called 'results'
dir.create("results")
```

After creating the results directory above, let's re-run `dir.exists` to see if 
now it exists.

```{r}
# Re-check if the results directory exists
dir.exists("results")
```

We can use the output of `dir.exists` to automatically create or hold off on 
creating a directory by putting this together in an `if` statement like below. 
Note that we put an exclamation point to signify that we want a directory to be
created only *if* `dir.exists(results)` is NOT equal to `TRUE`.

```{r}
# If 'results' directory doesn't exist...
if (!dir.exists("results")) {
  # ... create a 'results' directory
  dir.create("results")
}
```

Note that the `dir.exists` function will not work on files themselves.
In this case, there is an analogous function called `file.exists`.

Try using the `file.exists` function to see if the `metadata.tsv` file exists 
in the current directory.
Use the code chunk we set up for you below. 
Note that in our notebooks (and sometimes elsewhere), wherever you see a `<FILL_IN_THE_BLANK>` like in the chunk below, that is meant for you to replace with the correct phrase before you run the chunk (otherwise you will get an error).

```{r eval=FALSE}
# Replace the <PUT_FILE_NAME_HERE> with the name of the file you are looking for
# Remember to use quotes to make it a character string
file.exists(<PUT_FILE_NAME_HERE>)
```

## dplyr pipes
A nifty thing with the tidyverse is the pipes: `%>%`
This handy thing allows you to funnel the result of one expression to the next
making your code a little more streamlined.

For example, the output from this:  

```{r}
filter(metadata, sex == "F")
```  

...is the same as the output from this:  

```{r}
metadata %>% filter(sex == "F")
```  
  
This makes it so your code is cleaner and easier to read. 
Let's look at an example with our metadata of of how the same 
functions look with or without pipes:

*Example 1:* without pipes: 

```{r}
metadata_nopipe <- metadata
metadata_nopipe <- arrange(metadata_nopipe, histology)
metadata_nopipe <- filter(metadata_nopipe, follow_up_mths > 50)
metadata_nopipe <- select(metadata_nopipe, sample_id, sex, organism)
```
  
UGH, we have to repeat and assign `metadata_nopipe` so many times here! 
It's annoying and makes it harder for people to read. 
  
*Example 2:* Same result as 1 but with pipes!

```{r}
# Example of the same modifications as above but with pipes!
metadata_pipe <- metadata %>%
                 arrange(histology) %>%
                 filter(follow_up_mths > 50) %>%
                 select(sample_id, sex, organism)
```

Let's double check that these are the same by using the function, all.equal: 

```{r}
all.equal(metadata_nopipe, metadata_pipe)
```

`all.equal` is letting us know that these two objects are the same. 
(You can use all.equal in other instances and adjust the parameters depending on
how exact of a match you are looking for. )

Now that hopefully you are convinced that tidyverse helps your code to be neater and
easier to use and read, let's go through some of the popular tidyverse functions
and so we can create pipelines like this. 

## Common tidyverse functions

Let's say we wanted to filter this gene expression dataset to particular sample
groups.
In order to do this, we would use the function `filter` as well as a logic statement.

```{r}
# Here let's filter the data to have only females
metadata %>% filter(sex == "F")
```

We can use filter similarly for numeric statements.  

```{r}
# Here let's filter the data to have people only older than 
metadata %>% filter(age_mths > 100)
```

What if we wanted filter this dataset to males who are older than 100 months? 
Let's add another filtering argument to this filter.

```{r }
metadata %>% filter(age_mths > 100, sex == "F")
```

Let's build on to this pipe and keep only some of these variables with the 
`select` function. 

```{r}
metadata %>% filter(age_mths > 100, sex == "F") %>%
             select(sample_id, histology, metastasis)
```

Let's say we wanted to arrange this dataset so that the patients were arranged
youngest to oldest.
In order to do this, we would use the function `arrange` as well as the variable
we would like to sort by (in this case `age_mths`).

```{r}
metadata %>% arrange(age_mths) 
```

What if we want the the oldest patients at the top of this dataset instead? 
We can use the same function, but instead use the `desc` function too. 

```{r}
metadata %>% arrange(desc(age_mths))
``` 

What if we would like to create new variables? 
For that we use `mutate` function. 
Let's convert the ages that are in months to years and make that into a new variable.
Here we are also using the `round` function from base R to limit the number of 
decimal points in our new variable to 2.

```{r}
metadata %>% 
  mutate(age_yrs = round(age_mths/12, 2))
```

What if we want to obtain summary statistics for a variable? 
The `summarize` function allows us to calculate summary statistics for a column. 
Here we will use summarize to obtain an overall mean age in months. 

```{r}
metadata %>% summarize(mean(age_mths))
```

What if we'd like to obtain a summary statistics but have them for various groups?
Conveniently named, there's a function called `group_by` that seamlessly 
allows us to do this. 
Also note that `group_by` allows us to group by multiple variables at a time if 
you want to.

```{r}
metadata_summary <- metadata %>%
      group_by(sex) %>% 
      summarize(mean(age_mths))
```

Let's use `head(metadata_summary)` so we can look at a preview of what we made:

```{r}
head(metadata_summary)
```

## A brief intro to the `apply` family of functions

In the previous section, we used the `summarize` section to calculate summary
statistics for variables. 
However, in base R there the `apply` family of functions can be an alternative 
methods for performing transformations across a data.frame, matrix or for other 
object structures. 

We will practice using `apply` here. 
First, we are going to make a random matrix for us to practice `apply` functions 
on.
Question: What should we do before this step to make this *randomly* created 
matrix reproducible? 

```{r}
# Right! We should set the seed!
set.seed(12345)

# Make a matrix for apply practice
num_matrix <- matrix(rnorm(24), ncol = 4, nrow = 6)
```

The second argument in `apply` specifies whether we are applying something 
across rows or across columns (1 for rows, 2 for columns).

```{r}
# Calculate row means
row_means <- apply(num_matrix, 1, mean) # Notice we are using 1 here

# What dimensions will row_means have? 
str(row_means)
```

Now let's investigate the same set up, but use 2 to `apply` over the columns of
our matrix.

```{r}
# Calculate column means
col_means <- apply(num_matrix, 2, mean) # Notice we use 2 here

# What dimensions will col_means have? 
str(col_means)
```

Although the `apply` functions may not be as easy to use as the `tidyverse` 
functions, for some applications, `apply` methods can be better suited.
In this workshop, we will not delve too deeply into the various other apply 
functions (`tapply`, `lapply`, etc.) but you can read more examples 
about them [here](https://www.guru99.com/r-apply-sapply-tapply.html).

## Save data to files

#### Save to TSV files

Let's write this data we edited to a file.
To do this, we can use the `readr` library of `write` functions. 
Note that the second argument of `write_tsv` needs to be a character string that 
contains our `file.path` to the new file we would like to create.
Remember that we created a `results` directory to put our output in. 
But if we want to save our data to a directory other than our working directory, 
we need to specify this. 
This is what we will use the `file.path` function for. 
Let's look at what `file.path` does, by taking a look at the print out of it 
from examples below.

```{r}
# Which of these file paths is what we want to use to save our data to the
# results directory we created at the beginning of this notebook?
file.path("docker-install", "metadata.tsv")
file.path("results", "metadata_clean.tsv")
file.path("metadata_clean.tsv", "results")
```

Replace `<NEW_FILE_PATH>` below with the `file.path` from above that will 
successfully save our file to the `results` folder 

```{r eval=FALSE}
# Write our data.frame to a TSV file
write_tsv(metadata_summary, <NEW_FILE_PATH>)
```

Check in your `results` directory to see if your new file has successfully saved.

#### Save to RDS files

For this example we have been working with `data.frame`s, however, in other 
situations we may want to save more complicated structure objects or very large 
objects. 
RDS files may be a better option in these instances.
RDS is R's special file format for holding data exactly as you have it in your 
R environment. 
RDS files can also be compressed, meaning they will take up less space on your 
computer. 
Let's save our data to an RDS file in our `results` folder.
You will need to replace the `.tsv` with `.RDS`, but you can use what we 
determined as our `file.path` for the last chunk as your template. 

```{r eval=FALSE}
# Write your object to an RDS file
write_rds(metadata_summary, <PUT_CORRECT_FILE_PATH_HERE>)
```

#### Read an RDS file

Since now you have learned the `readr` functions: `read_tsv`, `write_tsv`, and 
now, `write_rds`, what do you suppose the function you will need to read your 
RDS file is called? 
Use that function here to re-import your data in the chunk we set up for you
below.

```{r eval=FALSE}
# Read in your RDS file
reimport_df <- <PUT_FUNCTION_NAME>(file.path("results", "metadata_clean.RDS"))
```

As is good practice, we will end this session by printing out our session info. 

#### Session Info: 

```{r}
sessionInfo()
```
